# -*- coding: utf-8 -*-
"""Web Phising.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1pjjZVJtmwWmmcj0TIaFmJtixIf6Md_TW
"""

# Commented out IPython magic to ensure Python compatibility.
import pandas as pd
import numpy as np
import seaborn as sns

from sklearn.linear_model import LogisticRegression
from sklearn.tree import DecisionTreeClassifier
from sklearn.ensemble import RandomForestClassifier
from sklearn.model_selection import train_test_split,cross_val_score
from matplotlib import pyplot as plt
# %matplotlib inline
from sklearn.metrics import accuracy_score,confusion_matrix,classification_report

df = pd.read_csv('drive/MyDrive/Dataset/Phising/phishing.csv')
df.head(12000)

df.isnull().sum()

df.describe()

X= df.drop(columns='class')
X.head()

Y=df['class']
Y=pd.DataFrame(Y)
Y.head()

train_X,test_X,train_Y,test_Y=train_test_split(X,Y,test_size=0.3,random_state=2)

print(train_X.shape)
print(test_X.shape)
print(train_Y.shape)
print(test_Y.shape)

# Commented out IPython magic to ensure Python compatibility.
from sklearn.linear_model import LogisticRegression
from matplotlib import pyplot as plt
import seaborn as sns
# %matplotlib inline
from sklearn.metrics import accuracy_score,confusion_matrix,classification_report
from sklearn.metrics import roc_auc_score, roc_curve

logreg=LogisticRegression()
model_1=logreg.fit(train_X,train_Y)

logreg_predict= model_1.predict(test_X)
print("Akurasi : ",accuracy_score(logreg_predict,test_Y))
print('Roc Score :',roc_auc_score(logreg_predict,test_Y ))
print(classification_report(logreg_predict,test_Y))

log_fpr, log_tpr, _ = roc_curve(logreg_predict,test_Y)
log_auc = roc_auc_score(logreg_predict,test_Y)
plt.plot(log_fpr, log_tpr, marker='.', label='LOG : (AUCROC = %.3f)' % log_auc)
plt.title('ROC Plot')
plt.xlabel('False Positive Rate')
plt.ylabel('True Positive Rate')
plt.legend()
plt.show()

print(classification_report(logreg_predict,test_Y))

from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score

def plot_confusion_matrix(test_Y, predict_y):
 C = confusion_matrix(test_Y, predict_y)
 A =(((C.T)/(C.sum(axis=1))).T)
 B =(C/C.sum(axis=0))
 plt.figure(figsize=(20,4))
 labels = [1,2]
 cmap=sns.light_palette("blue")
 plt.subplot(1, 3, 1)
 sns.heatmap(C, annot=True, cmap=cmap, fmt=".3f", xticklabels=labels, yticklabels=labels)
 plt.xlabel('Predicted Class')
 plt.ylabel('Original Class')
 plt.title("Confusion matrix")
 plt.subplot(1, 3, 2)
 sns.heatmap(B, annot=True, cmap=cmap, fmt=".3f", xticklabels=labels, yticklabels=labels)
 plt.xlabel('Predicted Class')
 plt.ylabel('Original Class')
 plt.title("Recal matrix")
 plt.subplot(1, 3, 3)
 sns.heatmap(A, annot=True, cmap=cmap, fmt=".3f", xticklabels=labels, yticklabels=labels)
 plt.xlabel('Predicted Class')
 plt.ylabel('Original Class')
 plt.title("Precision matrix")
 plt.show()

def plot_confusion_matrix(test_Y, predict_y):
 C = confusion_matrix(test_Y, predict_y)
 A =(((C.T)/(C.sum(axis=1))).T)
 B =(C/C.sum(axis=0))
 plt.figure(figsize=(20,4))
 labels = [1,2]
 cmap=sns.light_palette("blue")
 plt.subplot(1, 3, 1)
 sns.heatmap(C, annot=True, cmap=cmap, fmt=".3f", 
             xticklabels=labels, yticklabels=labels)
 plt.xlabel('Predicted Class')
 plt.ylabel('Original Class')
 plt.title("Confusion matrix")

plot_confusion_matrix(test_Y, logreg_predict)

log_fpr, log_tpr, _ = roc_curve(logreg_predict,test_Y)
log_auc = roc_auc_score(logreg_predict,test_Y)
plt.plot(log_fpr, log_tpr, marker='.', label='Logistic regression : (ROC = %.3f)' % log_auc)

plt.title('ROC Plot')
plt.xlabel('False Positive Rate')
plt.ylabel('True Positive Rate')
plt.legend()
plt.show()

from sklearn.tree import DecisionTreeClassifier
dtree=DecisionTreeClassifier()
model_3=dtree.fit(train_X,train_Y)
dtree_predict=model_3.predict(test_X)

accuracy_score(dtree_predict,test_Y)
print('Akurasi Decitsion Tree :',accuracy_score(dtree_predict,test_Y))
print('Roc Score :',roc_auc_score(dtree_predict,test_Y))
print(classification_report(dtree_predict,test_Y))

dtr_fpr, dtr_tpr, _ = roc_curve(dtree_predict,test_Y)
dtr_auc = roc_auc_score(dtree_predict,test_Y)
plt.plot(dtr_fpr, dtr_tpr, marker='.', label='Decision Tree : (ROC = %.3f)' % dtr_auc)


plt.title('ROC Plot')
plt.xlabel('False Positive Rate')
plt.ylabel('True Positive Rate')
plt.legend()
plt.show()

print(classification_report(dtree_predict,test_Y))

plot_confusion_matrix(test_Y, dtree_predict)

from sklearn.ensemble import RandomForestClassifier
rfc=RandomForestClassifier()
model_4=rfc.fit(train_X,train_Y)
rfc_predict=model_4.predict(test_X)

print('Akurasi :', accuracy_score(rfc_predict,test_Y))
print('Roc Score :',roc_auc_score(rfc_predict,test_Y))
print(classification_report(rfc_predict,test_Y))

print(classification_report(rfc_predict,test_Y))

plot_confusion_matrix(test_Y, rfc_predict)

rfc_fpr, rfc_tpr, _ = roc_curve(rfc_predict,test_Y)
rfc_auc = roc_auc_score(rfc_predict,test_Y)
plt.plot(rfc_fpr, rfc_tpr, marker='.', label='Random Forest : (ROC = %.3f)' % rfc_auc)


plt.title('ROC Plot')
plt.xlabel('False Positive Rate')
plt.ylabel('True Positive Rate')
plt.legend()
plt.show()

print('Roc Score Logistic Regression:',roc_auc_score(logreg_predict,test_Y ))
print('Roc Score Decission Tree:',roc_auc_score(dtree_predict,test_Y))
print('Roc Score Random Forest :',roc_auc_score(rfc_predict,test_Y))

lgr_fpr, lgr_tpr, _ = roc_curve(logreg_predict,test_Y)
dtr_fpr, dtr_tpr, _ = roc_curve(dtree_predict,test_Y)
rfc_fpr, rfc_tpr, _ = roc_curve(rfc_predict,test_Y)



lgr_auc = roc_auc_score(logreg_predict,test_Y)
dtr_auc = roc_auc_score(dtree_predict,test_Y)
rfc_auc = roc_auc_score(rfc_predict,test_Y)

plt.plot(lgr_fpr, lgr_tpr, marker='.', label='Logistic Regression : (ROC = %.3f)' % lgr_auc)
plt.plot(dtr_fpr, dtr_tpr, marker='.', label='Decision Tree : (ROC = %.3f)' % dtr_auc)
plt.plot(rfc_fpr, rfc_tpr, marker='.', label='Random Forest : (ROC = %.3f)' % rfc_auc)


plt.title('ROC Plot')
plt.xlabel('False Positive Rate')
plt.ylabel('True Positive Rate')
plt.legend()
plt.show()

print('Logistic Regression Accuracy:',accuracy_score(logreg_predict,test_Y))
print('Decision Tree Classifier Accuracy:',accuracy_score(dtree_predict,test_Y))
print('Random Forest Classifier Accuracy:',accuracy_score(rfc_predict,test_Y))